name: Deploy to AWS ECS

on:
  push:
    branches: [main]
    paths:
      - "backend/**"
      - "frontend/**"
      - "infra/**"
  workflow_dispatch:
    inputs:
      deploy_mode:
        description: "Target environment mode for Terraform/app config"
        required: false
        default: production
        type: choice
        options:
          - sandbox
          - production
      tf_state_key:
        description: "Terraform backend state key override (example: sandbox/terraform.tfstate)"
        required: false
        default: ""
        type: string

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1
  PROJECT_NAME: arbiter-ai
  DEFAULT_DEPLOY_MODE: production
  DEFAULT_TF_STATE_KEY: prod/terraform.tfstate

jobs:
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      backend: ${{ steps.filter.outputs.backend }}
      frontend: ${{ steps.filter.outputs.frontend }}
      infra: ${{ steps.filter.outputs.infra }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          base: main
          filters: |
            backend:
              - 'backend/**'
            frontend:
              - 'frontend/**'
            infra:
              - 'infra/**'

  infra-prebuild-check:
    name: Infra Pre-Build Check
    runs-on: ubuntu-latest
    needs: changes
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~> 1.5"

      - name: Validate infra inventory + Terraform config
        run: |
          python3 infra/scripts/check_infra_inventory.py --check
          terraform -chdir=infra/terraform fmt -check -recursive
          terraform -chdir=infra/terraform init -backend=false
          terraform -chdir=infra/terraform validate

  build-backend:
    name: Build & Push Backend
    runs-on: ubuntu-latest
    needs: [changes, infra-prebuild-check]
    if: needs.changes.outputs.backend == 'true'
    outputs:
      image_tag: ${{ steps.meta.outputs.tag }}
    steps:
      - uses: actions/checkout@v4

      - name: Set image tag
        id: meta
        run: echo "tag=sha-$(git rev-parse --short HEAD)" >> "$GITHUB_OUTPUT"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build & push backend image
        env:
          REGISTRY: ${{ steps.ecr-login.outputs.registry }}
          TAG: ${{ steps.meta.outputs.tag }}
        run: |
          docker build -t $REGISTRY/$PROJECT_NAME-backend:$TAG -t $REGISTRY/$PROJECT_NAME-backend:latest -f backend/Dockerfile backend/
          docker push $REGISTRY/$PROJECT_NAME-backend:$TAG
          docker push $REGISTRY/$PROJECT_NAME-backend:latest

  build-frontend:
    name: Build & Push Frontend
    runs-on: ubuntu-latest
    needs: [changes, infra-prebuild-check]
    if: needs.changes.outputs.frontend == 'true'
    outputs:
      image_tag: ${{ steps.meta.outputs.tag }}
    steps:
      - uses: actions/checkout@v4

      - name: Set image tag
        id: meta
        run: echo "tag=sha-$(git rev-parse --short HEAD)" >> "$GITHUB_OUTPUT"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build & push frontend image
        env:
          REGISTRY: ${{ steps.ecr-login.outputs.registry }}
          TAG: ${{ steps.meta.outputs.tag }}
          NEXT_PUBLIC_API_URL: ${{ secrets.NEXT_PUBLIC_API_URL || '/api/v1' }}
        run: |
          docker build --build-arg NEXT_PUBLIC_API_URL="$NEXT_PUBLIC_API_URL" -t $REGISTRY/$PROJECT_NAME-frontend:$TAG -t $REGISTRY/$PROJECT_NAME-frontend:latest -f frontend/Dockerfile frontend/
          docker push $REGISTRY/$PROJECT_NAME-frontend:$TAG
          docker push $REGISTRY/$PROJECT_NAME-frontend:latest

  terraform:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: [changes, infra-prebuild-check, build-backend, build-frontend]
    if: always() && !cancelled()
    defaults:
      run:
        working-directory: infra/terraform
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~> 1.5"

      - name: Resolve deploy context
        id: context
        run: |
          DEPLOY_MODE="${{ github.event.inputs.deploy_mode }}"
          if [ -z "$DEPLOY_MODE" ]; then
            DEPLOY_MODE="${{ vars.DEPLOY_MODE }}"
          fi
          if [ -z "$DEPLOY_MODE" ]; then
            DEPLOY_MODE="${DEFAULT_DEPLOY_MODE}"
          fi

          TF_STATE_KEY="${{ github.event.inputs.tf_state_key }}"
          if [ -z "$TF_STATE_KEY" ]; then
            TF_STATE_KEY="${{ vars.TF_STATE_KEY }}"
          fi
          if [ -z "$TF_STATE_KEY" ]; then
            TF_STATE_KEY="${DEPLOY_MODE}/terraform.tfstate"
          fi

          echo "deploy_mode=${DEPLOY_MODE}" >> "$GITHUB_OUTPUT"
          echo "tf_state_key=${TF_STATE_KEY}" >> "$GITHUB_OUTPUT"
          TF_VARS_FILE="environments/${DEPLOY_MODE}.tfvars"
          if [ -f "$TF_VARS_FILE" ]; then
            echo "tf_vars_file=${TF_VARS_FILE}" >> "$GITHUB_OUTPUT"
          else
            echo "tf_vars_file=" >> "$GITHUB_OUTPUT"
          fi

      - name: Terraform Init
        run: terraform init -backend-config="key=${{ steps.context.outputs.tf_state_key }}"

      - name: Import existing ECS services
        env:
          # Import evaluates the Terraform configuration, so required vars must
          # be present here too (not only in terraform plan/apply).
          TF_VAR_environment: ${{ steps.context.outputs.deploy_mode }}
          TF_VAR_app_mode: ${{ steps.context.outputs.deploy_mode }}
          TF_VAR_app_env: ${{ steps.context.outputs.deploy_mode }}
          TF_VAR_secrets_manager_arn: ${{ secrets.SECRETS_MANAGER_ARN }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
        run: |
          # Best-effort import: If services exist but aren't in state, bring them in.
          # If they don't exist (fresh deploy) or are already in state, this fails safely (|| true).
          # The subsequent 'plan' will determine the actual required changes.
          IMPORT_ARGS=()
          if [ -n "${{ steps.context.outputs.tf_vars_file }}" ]; then
            IMPORT_ARGS+=("-var-file=${{ steps.context.outputs.tf_vars_file }}")
          fi
          PROJECT_NAME="${{ env.PROJECT_NAME }}"
          for svc in backend frontend worker beat; do
            echo "Attempting import for aws_ecs_service.${svc}..."
            terraform import "${IMPORT_ARGS[@]}" "aws_ecs_service.${svc}" "${PROJECT_NAME}-cluster/${PROJECT_NAME}-${svc}" || true
          done

      - name: Determine image tags
        id: tags
        run: |
          if [ -n "${{ needs.build-backend.outputs.image_tag }}" ]; then
            echo "backend_tag=${{ needs.build-backend.outputs.image_tag }}" >> "$GITHUB_OUTPUT"
          else
            echo "backend_tag=latest" >> "$GITHUB_OUTPUT"
          fi
          if [ -n "${{ needs.build-frontend.outputs.image_tag }}" ]; then
            echo "frontend_tag=${{ needs.build-frontend.outputs.image_tag }}" >> "$GITHUB_OUTPUT"
          else
            echo "frontend_tag=latest" >> "$GITHUB_OUTPUT"
          fi

      - name: Terraform Plan
        run: |
          PLAN_ARGS=()
          if [ -n "${{ steps.context.outputs.tf_vars_file }}" ]; then
            PLAN_ARGS+=("-var-file=${{ steps.context.outputs.tf_vars_file }}")
          fi
          terraform plan "${PLAN_ARGS[@]}" \
            -var="environment=${{ steps.context.outputs.deploy_mode }}" \
            -var="app_mode=${{ steps.context.outputs.deploy_mode }}" \
            -var="app_env=${{ steps.context.outputs.deploy_mode }}" \
            -var="backend_image_tag=${{ steps.tags.outputs.backend_tag }}" \
            -var="frontend_image_tag=${{ steps.tags.outputs.frontend_tag }}" \
            -var="secrets_manager_arn=${{ secrets.SECRETS_MANAGER_ARN }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -out=tfplan

      - name: Terraform Apply
        run: terraform apply -auto-approve tfplan

  deploy:
    name: Deploy Services
    runs-on: ubuntu-latest
    needs: [changes, build-backend, build-frontend, terraform]
    if: always() && needs.terraform.result == 'success' && (needs.build-backend.result == 'success' || needs.build-frontend.result == 'success')
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy updated backend
        if: needs.build-backend.result == 'success'
        run: |
          aws ecs update-service --cluster $PROJECT_NAME-cluster --service $PROJECT_NAME-backend --force-new-deployment
          aws ecs update-service --cluster $PROJECT_NAME-cluster --service $PROJECT_NAME-worker --force-new-deployment
          aws ecs update-service --cluster $PROJECT_NAME-cluster --service $PROJECT_NAME-beat --force-new-deployment

      - name: Deploy updated frontend
        if: needs.build-frontend.result == 'success'
        run: |
          aws ecs update-service --cluster $PROJECT_NAME-cluster --service $PROJECT_NAME-frontend --force-new-deployment

      - name: Wait for services to stabilize
        run: |
          aws ecs wait services-stable --cluster $PROJECT_NAME-cluster --services $PROJECT_NAME-backend $PROJECT_NAME-frontend $PROJECT_NAME-worker $PROJECT_NAME-beat
